"""
Response Agent for generating natural language responses from query results.

This module provides a ResponseAgent class that takes query results and generates
a natural language response that answers the user's question.
"""

import json
import traceback
import datetime
import logging
from typing import Dict, List, Any, Optional
from gemini_client import GeminiClient

# Custom JSON encoder to handle date objects
class DateTimeEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, (datetime.date, datetime.datetime)):
            return obj.isoformat()
        return super().default(obj)

class ResponseAgent:
    """
    Agent for generating natural language responses from query results.
    """
    
    def __init__(self, gemini_client: GeminiClient):
        """
        Initialize the Response Agent with a Gemini client.
        
        Args:
            gemini_client: The Gemini client for generating responses
        """
        self.gemini_client = gemini_client
        self.logger = logging.getLogger(__name__)
        
    def generate_response(self, question: str, results: Dict[str, List[Dict[str, Any]]], 
                          constraints: Optional[Dict[str, Any]] = None) -> str:
        """
        Generate a natural language response from query results.
        
        Args:
            question: The original user question
            results: Dictionary of query results, keyed by result_id
            constraints: Optional constraints extracted from the question
            
        Returns:
            A natural language response that answers the user's question
        """
        try:
            self.logger.info(f"\nGenerating response for question: {question}")
            self.logger.info(f"Results type: {type(results)}")
            self.logger.info(f"Results keys: {results.keys() if isinstance(results, dict) else 'Not a dict'}")
            
            # Ensure results is a dictionary
            if isinstance(results, str):
                try:
                    results = json.loads(results)
                    self.logger.info("Successfully parsed results from JSON string")
                except json.JSONDecodeError:
                    self.logger.error(f"Error parsing results JSON: {results[:100]}...")
                    traceback.print_exc()
                    results = {}
            
            # Ensure constraints is a dictionary
            if constraints is None:
                constraints = {}
                self.logger.info("No constraints provided, using empty dict")
            elif isinstance(constraints, str):
                try:
                    constraints = json.loads(constraints)
                    self.logger.info("Successfully parsed constraints from JSON string")
                except json.JSONDecodeError:
                    self.logger.error(f"Error parsing constraints JSON: {constraints[:100]}...")
                    traceback.print_exc()
                    constraints = {}
            
            # Pre-process results to calculate totals and other metrics
            self.logger.info("Pre-processing results...")
            processed_results = self._preprocess_results(results)
            self.logger.info(f"Processed results keys: {processed_results.keys()}")
            
            # Create a prompt for the response generation
            self.logger.info("Creating response prompt...")
            prompt = self._create_response_prompt(question, processed_results, constraints)
            
            # Generate the response
            self.logger.info("Generating response using Gemini...")
            self.logger.info(f"Sending prompt to Gemini:\n{prompt}")
            try:
                response = self.gemini_client.generate_content(prompt)
                self.logger.info(f"Raw response from Gemini:\n{response}")
            
                if not response:
                    self.logger.error("No response generated from Gemini")
                    return self._generate_default_response(processed_results)
                
                # Extract the actual text from the response
                if isinstance(response, str):
                    response_text = response
                else:
                    # Handle Vertex AI response object
                    response_text = getattr(response, 'text', '')
                    if not response_text:
                        # Try to get the first candidate's text
                        candidates = getattr(response, 'candidates', [])
                        if candidates and len(candidates) > 0:
                            response_text = getattr(candidates[0], 'text', '')
                
                if not response_text:
                    self.logger.error("Empty text in Gemini response")
                    return self._generate_default_response(processed_results)
                
                # Clean up the response text
                response_text = response_text.strip()
                
                # Ensure response is not too long
                MAX_LENGTH = 2900
                if len(response_text) > MAX_LENGTH:
                    self.logger.warning(f"Response too long ({len(response_text)} chars), truncating...")
                    # Try to truncate at a sentence boundary
                    truncated = response_text[:MAX_LENGTH]
                    last_period = truncated.rfind('.')
                    if last_period > 0:
                        response_text = truncated[:last_period + 1]
                    else:
                        response_text = truncated + "..."
                
                # Format numbers with commas
                response_text = self._format_numbers_with_commas(response_text)
                
                self.logger.info(f"Successfully generated response: {response_text}")
                return response_text
                
            except Exception as e:
                self.logger.error(f"Error getting response from Gemini: {str(e)}")
                self.logger.error(traceback.format_exc())
                return self._generate_default_response(processed_results)
            
        except Exception as e:
            self.logger.error(f"Error generating response: {str(e)}")
            traceback.print_exc()
            return self._generate_default_response(processed_results)
        
    def _preprocess_results(self, results: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Any]:
        """
        Pre-process results to calculate totals and other metrics.
        
        Args:
            results: Dictionary of query results, keyed by result_id
            
        Returns:
            Processed results with additional calculated metrics
        """
        self.logger.info("\nPreprocessing results...")
        self.logger.info(f"Input results type: {type(results)}")
        self.logger.info(f"Input results keys: {results.keys() if isinstance(results, dict) else 'Not a dict'}")
        
        processed_results = results.copy()
        
        # Process each result set
        for result_id, result_data in results.items():
            self.logger.info(f"\nProcessing result set: {result_id}")
            self.logger.info(f"Result data type: {type(result_data)}")
            
            if not isinstance(result_data, dict) or not result_data.get("data"):
                self.logger.info(f"No processable data for result set {result_id}")
                continue
                
            # The data should already contain its own summary
            # We don't need to calculate anything here as each KPI processor
            # should provide its own summary statistics
            
            self.logger.info(f"Preserving existing summary for {result_id}")
                
        self.logger.info("\nFinal processed results:")
        self.logger.info(f"Keys: {processed_results.keys()}")
        return processed_results
        
    def _create_response_prompt(self, question: str, results: Dict[str, List[Dict[str, Any]]], 
                               constraints: Optional[Dict[str, Any]] = None) -> str:
        """
        Create a prompt for generating a response.
        
        Args:
            question: The original user question
            results: Dictionary of query results, keyed by result_id
            constraints: Optional constraints extracted from the question
            
        Returns:
            A prompt for the Gemini model
        """
        self.logger.info("\nCreating response prompt...")
        
        # Extract result data
        result_data = None
        for result_id, data in results.items():
            if isinstance(data, dict) and data.get("status") == "success":
                result_data = data.get("data", {})
                break
        
        if not result_data or not result_data.get("data"):
            return f"""You are a helpful analytics assistant.
            The user asked: "{question}"
            Unfortunately, no data was found. Please apologize and suggest they try different parameters or rephrase their question.
            
            IMPORTANT: Keep your response under 2900 characters and format numbers with commas."""
        
        # Format the data for the prompt
        summary = result_data.get("summary", {})
        data_points = result_data.get("data", [])
        
        # Calculate some basic statistics if we have numeric data
        stats = {}
        if data_points:
            for key in data_points[0].keys():
                if all(isinstance(point.get(key), (int, float)) for point in data_points):
                    values = [point[key] for point in data_points]
                    stats[key] = {
                        "total": sum(values),
                        "average": sum(values) / len(values),
                        "max": max(values),
                        "min": min(values)
                    }
        
        # Create summary points
        summary_points = []
        summary_points.append(f"- Time Period: {summary.get('time_period', 'Not specified')}")
        summary_points.append(f"- Location: {summary.get('location', 'Not specified')}")
        summary_points.append(f"- Total Records: {summary.get('total_records', len(data_points))}")
        
        # Add order statistics if available
        order_stats = summary.get('total_orders', {})
        if order_stats:
            summary_points.append("- Order Statistics:")
            summary_points.append(f"  - Total Orders: {order_stats.get('total', 0):,.0f}")
            summary_points.append(f"  - Average Orders per Day: {order_stats.get('average', 0):,.2f}")
            summary_points.append(f"  - Maximum Orders in a Day: {order_stats.get('max', 0):,.0f}")
            summary_points.append(f"  - Minimum Orders in a Day: {order_stats.get('min', 0):,.0f}")
        
        # Get sample data points
        sample_points = []
        for point in data_points[:5]:
            formatted_point = []
            for k, v in point.items():
                if isinstance(v, (datetime.date, datetime.datetime)):
                    formatted_point.append(f"{k}: {v.strftime('%Y-%m-%d')}")
                elif isinstance(v, (int, float)):
                    formatted_point.append(f"{k}: {v:,.0f}")
                else:
                    formatted_point.append(f"{k}: {v}")
            sample_points.append("- " + ", ".join(formatted_point))
        
        prompt = f"""You are a helpful analytics assistant. Generate a concise response to the user's question.

Question: "{question}"

Data Summary:
{chr(10).join(summary_points)}

{f'''Sample Data Points:
{chr(10).join(sample_points)}''' if sample_points else ''}

Instructions:
1. Start with a direct answer addressing the user's question
2. Include key statistics and insights from the data
3. Mention the time period and location being analyzed
4. Format large numbers with commas for readability
5. Keep the response under 2900 characters to ensure it fits in a single message
6. Focus on the most relevant information for the user's question
7. Use clear paragraph breaks for readability
8. Avoid using special characters or emojis that might cause formatting issues

Example format:
"For {location} during {time_period}, there were {total_orders:,} total orders, averaging {average_orders:,.0f} orders per day. The highest daily volume was {max_orders:,} orders, while the lowest was {min_orders:,} orders."

Remember to be helpful and informative while maintaining a natural conversational tone."""
        
        return prompt
        
    def generate_error_response(self, question: str, error: str) -> str:
        """
        Generate an error response when query execution fails.
        
        Args:
            question: The original user question
            error: The error message
            
        Returns:
            A natural language error response
        """
        prompt = f"""
You are an analytics assistant that helps users understand their data.
Unfortunately, there was an error processing the following question:

USER QUESTION:
{question}

ERROR:
{error}

Please generate a friendly and helpful error message that:
1. Acknowledges the error
2. Explains what might have gone wrong in non-technical terms
3. Suggests how the user might rephrase or clarify their question
4. Maintains a helpful and apologetic tone

Your response should be concise and focus on how the user can get a successful response next time.
"""
        
        response = self.gemini_client.generate_content(prompt)
        return response 

    def _generate_default_response(self, results: Dict[str, Any]) -> str:
        """Generate a default response when Gemini fails"""
        try:
            first_result = next(iter(results.values()))
            if first_result and first_result.get("status") == "success":
                data = first_result.get("data", {})
                summary = data.get("summary", {})
                order_stats = summary.get("total_orders", {})
                
                return (
                    f"For {summary.get('location', 'the specified location')} during the period "
                    f"{summary.get('time_period', 'specified')}, there were {order_stats.get('total', 0):,.0f} "
                    f"total orders, averaging {order_stats.get('average', 0):,.2f} orders per day. "
                    f"The highest daily volume was {order_stats.get('max', 0):,.0f} orders, while the "
                    f"lowest was {order_stats.get('min', 0):,.0f} orders."
                )
            return "I apologize, but I couldn't generate a response from the data."
        except Exception as e:
            self.logger.error(f"Error generating default response: {str(e)}")
            return "I apologize, but I encountered an error while generating the response."

    def _format_numbers_with_commas(self, text: str) -> str:
        """Format numbers in text with commas"""
        import re
        
        def format_number(match):
            number = match.group(0)
            try:
                # Handle decimal numbers
                if '.' in number:
                    parts = number.split('.')
                    return f"{int(parts[0]):,}.{parts[1]}"
                # Handle integers
                return f"{int(number):,}"
            except:
                return number
        
        # Find numbers (including decimals) not part of a word
        pattern = r'\b\d+(?:\.\d+)?\b'
        return re.sub(pattern, format_number, text) 